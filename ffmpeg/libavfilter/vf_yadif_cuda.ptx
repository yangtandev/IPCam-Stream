//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32965470
// Cuda compilation tools, release 12.2, V12.2.91
// Based on NVVM 7.0.1
//

.version 8.2
.target sm_60
.address_size 64

	// .globl	yadif_uchar

.visible .entry yadif_uchar(
	.param .u64 yadif_uchar_param_0,
	.param .u64 yadif_uchar_param_1,
	.param .u64 yadif_uchar_param_2,
	.param .u64 yadif_uchar_param_3,
	.param .u32 yadif_uchar_param_4,
	.param .u32 yadif_uchar_param_5,
	.param .u32 yadif_uchar_param_6,
	.param .u32 yadif_uchar_param_7,
	.param .u32 yadif_uchar_param_8,
	.param .u32 yadif_uchar_param_9,
	.param .u32 yadif_uchar_param_10,
	.param .u8 yadif_uchar_param_11
)
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<15>;
	.reg .b32 	%r<250>;
	.reg .b64 	%rd<10>;


	ld.param.s8 	%rs1, [yadif_uchar_param_11];
	ld.param.u64 	%rd2, [yadif_uchar_param_0];
	ld.param.u64 	%rd3, [yadif_uchar_param_1];
	ld.param.u64 	%rd4, [yadif_uchar_param_2];
	ld.param.u64 	%rd5, [yadif_uchar_param_3];
	ld.param.u32 	%r57, [yadif_uchar_param_4];
	ld.param.u32 	%r58, [yadif_uchar_param_5];
	ld.param.u32 	%r54, [yadif_uchar_param_6];
	ld.param.u32 	%r55, [yadif_uchar_param_9];
	ld.param.u32 	%r56, [yadif_uchar_param_10];
	mov.u32 	%r59, %ntid.x;
	mov.u32 	%r60, %ctaid.x;
	mov.u32 	%r61, %tid.x;
	mad.lo.s32 	%r1, %r60, %r59, %r61;
	mov.u32 	%r62, %ntid.y;
	mov.u32 	%r63, %ctaid.y;
	mov.u32 	%r64, %tid.y;
	mad.lo.s32 	%r2, %r63, %r62, %r64;
	setp.ge.s32 	%p1, %r1, %r57;
	setp.ge.s32 	%p2, %r2, %r58;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB0_10;

	shr.u32 	%r65, %r2, 31;
	add.s32 	%r66, %r2, %r65;
	and.b32  	%r67, %r66, -2;
	sub.s32 	%r68, %r2, %r67;
	setp.eq.s32 	%p4, %r68, %r55;
	mad.lo.s32 	%r69, %r2, %r54, %r1;
	cvt.s64.s32 	%rd6, %r69;
	cvta.to.global.u64 	%rd7, %rd2;
	add.s64 	%rd1, %rd7, %rd6;
	@%p4 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_2;

$L__BB0_9:
	cvt.rn.f32.s32 	%f13, %r1;
	cvt.rn.f32.s32 	%f14, %r2;
	tex.2d.v4.u32.f32 	{%r242, %r243, %r244, %r245}, [%rd4, {%f13, %f14}];
	st.global.u8 	[%rd1], %r242;
	bra.uni 	$L__BB0_10;

$L__BB0_2:
	add.s32 	%r70, %r1, -3;
	cvt.rn.f32.s32 	%f4, %r70;
	add.s32 	%r71, %r2, -1;
	cvt.rn.f32.s32 	%f1, %r71;
	tex.2d.v4.u32.f32 	{%r3, %r4, %r5, %r6}, [%rd4, {%f4, %f1}];
	add.s32 	%r72, %r1, -2;
	cvt.rn.f32.s32 	%f5, %r72;
	tex.2d.v4.u32.f32 	{%r73, %r74, %r75, %r76}, [%rd4, {%f5, %f1}];
	add.s32 	%r77, %r1, -1;
	cvt.rn.f32.s32 	%f6, %r77;
	tex.2d.v4.u32.f32 	{%r78, %r79, %r80, %r81}, [%rd4, {%f6, %f1}];
	cvt.rn.f32.s32 	%f2, %r1;
	tex.2d.v4.u32.f32 	{%r82, %r83, %r84, %r85}, [%rd4, {%f2, %f1}];
	add.s32 	%r86, %r1, 1;
	cvt.rn.f32.s32 	%f7, %r86;
	tex.2d.v4.u32.f32 	{%r87, %r88, %r89, %r90}, [%rd4, {%f7, %f1}];
	add.s32 	%r91, %r1, 2;
	cvt.rn.f32.s32 	%f8, %r91;
	tex.2d.v4.u32.f32 	{%r7, %r8, %r9, %r10}, [%rd4, {%f8, %f1}];
	add.s32 	%r92, %r1, 3;
	cvt.rn.f32.s32 	%f9, %r92;
	tex.2d.v4.u32.f32 	{%r11, %r12, %r13, %r14}, [%rd4, {%f9, %f1}];
	add.s32 	%r93, %r2, 1;
	cvt.rn.f32.s32 	%f3, %r93;
	tex.2d.v4.u32.f32 	{%r15, %r16, %r17, %r18}, [%rd4, {%f4, %f3}];
	tex.2d.v4.u32.f32 	{%r19, %r20, %r21, %r22}, [%rd4, {%f5, %f3}];
	tex.2d.v4.u32.f32 	{%r94, %r95, %r96, %r97}, [%rd4, {%f6, %f3}];
	tex.2d.v4.u32.f32 	{%r98, %r99, %r100, %r101}, [%rd4, {%f2, %f3}];
	tex.2d.v4.u32.f32 	{%r102, %r103, %r104, %r105}, [%rd4, {%f7, %f3}];
	tex.2d.v4.u32.f32 	{%r106, %r107, %r108, %r109}, [%rd4, {%f8, %f3}];
	tex.2d.v4.u32.f32 	{%r23, %r24, %r25, %r26}, [%rd4, {%f9, %f3}];
	and.b32  	%r27, %r82, 255;
	and.b32  	%r28, %r98, 255;
	add.s32 	%r248, %r28, %r27;
	and.b32  	%r30, %r78, 255;
	and.b32  	%r31, %r94, 255;
	sub.s32 	%r110, %r30, %r31;
	abs.s32 	%r111, %r110;
	sub.s32 	%r112, %r27, %r28;
	abs.s32 	%r113, %r112;
	add.s32 	%r114, %r113, %r111;
	and.b32  	%r32, %r87, 255;
	and.b32  	%r33, %r102, 255;
	sub.s32 	%r115, %r32, %r33;
	abs.s32 	%r116, %r115;
	add.s32 	%r247, %r114, %r116;
	and.b32  	%r35, %r73, 255;
	sub.s32 	%r117, %r35, %r28;
	abs.s32 	%r118, %r117;
	sub.s32 	%r119, %r30, %r33;
	abs.s32 	%r120, %r119;
	add.s32 	%r121, %r120, %r118;
	and.b32  	%r36, %r106, 255;
	sub.s32 	%r122, %r27, %r36;
	abs.s32 	%r123, %r122;
	add.s32 	%r37, %r121, %r123;
	setp.ge.s32 	%p5, %r37, %r247;
	@%p5 bra 	$L__BB0_4;

	and.b32  	%r124, %r3, 255;
	sub.s32 	%r125, %r124, %r33;
	abs.s32 	%r126, %r125;
	sub.s32 	%r127, %r35, %r36;
	abs.s32 	%r128, %r127;
	add.s32 	%r129, %r128, %r126;
	and.b32  	%r130, %r23, 255;
	sub.s32 	%r131, %r30, %r130;
	abs.s32 	%r132, %r131;
	add.s32 	%r133, %r129, %r132;
	setp.lt.s32 	%p6, %r133, %r37;
	add.s32 	%r134, %r36, %r35;
	add.s32 	%r135, %r33, %r30;
	selp.b32 	%r248, %r134, %r135, %p6;
	min.s32 	%r247, %r133, %r37;

$L__BB0_4:
	and.b32  	%r42, %r19, 255;
	sub.s32 	%r136, %r27, %r42;
	abs.s32 	%r137, %r136;
	sub.s32 	%r138, %r32, %r31;
	abs.s32 	%r139, %r138;
	add.s32 	%r140, %r139, %r137;
	and.b32  	%r43, %r7, 255;
	sub.s32 	%r141, %r43, %r28;
	abs.s32 	%r142, %r141;
	add.s32 	%r44, %r140, %r142;
	setp.ge.s32 	%p7, %r44, %r247;
	@%p7 bra 	$L__BB0_6;

	add.s32 	%r143, %r31, %r32;
	and.b32  	%r144, %r15, 255;
	sub.s32 	%r145, %r32, %r144;
	abs.s32 	%r146, %r145;
	sub.s32 	%r147, %r43, %r42;
	abs.s32 	%r148, %r147;
	add.s32 	%r149, %r148, %r146;
	and.b32  	%r150, %r11, 255;
	sub.s32 	%r151, %r150, %r31;
	abs.s32 	%r152, %r151;
	add.s32 	%r153, %r149, %r152;
	setp.lt.s32 	%p8, %r153, %r44;
	add.s32 	%r154, %r42, %r43;
	selp.b32 	%r248, %r154, %r143, %p8;

$L__BB0_6:
	setp.eq.s32 	%p9, %r55, %r56;
	selp.b64 	%rd8, %rd4, %rd3, %p9;
	selp.b64 	%rd9, %rd5, %rd4, %p9;
	tex.2d.v4.u32.f32 	{%r155, %r156, %r157, %r158}, [%rd3, {%f2, %f1}];
	tex.2d.v4.u32.f32 	{%r159, %r160, %r161, %r162}, [%rd3, {%f2, %f3}];
	add.s32 	%r163, %r2, -2;
	cvt.rn.f32.s32 	%f10, %r163;
	tex.2d.v4.u32.f32 	{%r164, %r165, %r166, %r167}, [%rd8, {%f2, %f10}];
	cvt.rn.f32.s32 	%f11, %r2;
	tex.2d.v4.u32.f32 	{%r168, %r169, %r170, %r171}, [%rd8, {%f2, %f11}];
	add.s32 	%r172, %r2, 2;
	cvt.rn.f32.s32 	%f12, %r172;
	tex.2d.v4.u32.f32 	{%r173, %r174, %r175, %r176}, [%rd8, {%f2, %f12}];
	tex.2d.v4.u32.f32 	{%r177, %r178, %r179, %r180}, [%rd9, {%f2, %f10}];
	tex.2d.v4.u32.f32 	{%r181, %r182, %r183, %r184}, [%rd9, {%f2, %f11}];
	tex.2d.v4.u32.f32 	{%r185, %r186, %r187, %r188}, [%rd9, {%f2, %f12}];
	tex.2d.v4.u32.f32 	{%r189, %r190, %r191, %r192}, [%rd5, {%f2, %f1}];
	tex.2d.v4.u32.f32 	{%r193, %r194, %r195, %r196}, [%rd5, {%f2, %f3}];
	shr.u32 	%r47, %r248, 1;
	and.b32  	%r197, %r164, 255;
	and.b32  	%r198, %r177, 255;
	add.s32 	%r48, %r198, %r197;
	and.b32  	%r199, %r168, 255;
	and.b32  	%r200, %r181, 255;
	add.s32 	%r201, %r200, %r199;
	shr.u32 	%r49, %r201, 1;
	and.b32  	%r202, %r173, 255;
	and.b32  	%r203, %r185, 255;
	add.s32 	%r50, %r203, %r202;
	sub.s32 	%r204, %r199, %r200;
	abs.s32 	%r205, %r204;
	and.b32  	%r206, %r155, 255;
	sub.s32 	%r207, %r206, %r27;
	abs.s32 	%r208, %r207;
	and.b32  	%r209, %r159, 255;
	sub.s32 	%r210, %r209, %r28;
	abs.s32 	%r211, %r210;
	add.s32 	%r212, %r211, %r208;
	shr.u32 	%r213, %r212, 1;
	and.b32  	%r214, %r189, 255;
	sub.s32 	%r215, %r214, %r27;
	abs.s32 	%r216, %r215;
	and.b32  	%r217, %r193, 255;
	sub.s32 	%r218, %r28, %r217;
	abs.s32 	%r219, %r218;
	add.s32 	%r220, %r219, %r216;
	shr.u32 	%r221, %r220, 1;
	max.s32 	%r222, %r205, %r213;
	max.s32 	%r249, %r222, %r221;
	setp.ne.s16 	%p10, %rs1, 0;
	@%p10 bra 	$L__BB0_8;

	shr.u32 	%r223, %r50, 1;
	shr.u32 	%r224, %r48, 1;
	sub.s32 	%r225, %r224, %r27;
	sub.s32 	%r226, %r223, %r28;
	min.s32 	%r227, %r225, %r226;
	sub.s32 	%r228, %r49, %r27;
	sub.s32 	%r229, %r49, %r28;
	max.s32 	%r230, %r229, %r228;
	max.s32 	%r231, %r230, %r227;
	max.s32 	%r232, %r225, %r226;
	min.s32 	%r233, %r229, %r228;
	min.s32 	%r234, %r233, %r232;
	neg.s32 	%r235, %r231;
	max.s32 	%r236, %r249, %r234;
	max.s32 	%r249, %r236, %r235;

$L__BB0_8:
	add.s32 	%r237, %r249, %r49;
	setp.lt.s32 	%p11, %r237, %r47;
	selp.b32 	%r238, %r237, %r47, %p11;
	and.b32  	%r239, %r238, 255;
	sub.s32 	%r240, %r49, %r249;
	setp.gt.s32 	%p12, %r240, %r239;
	selp.b32 	%r241, %r240, %r238, %p12;
	st.global.u8 	[%rd1], %r241;

$L__BB0_10:
	ret;

}
	// .globl	yadif_ushort
.visible .entry yadif_ushort(
	.param .u64 yadif_ushort_param_0,
	.param .u64 yadif_ushort_param_1,
	.param .u64 yadif_ushort_param_2,
	.param .u64 yadif_ushort_param_3,
	.param .u32 yadif_ushort_param_4,
	.param .u32 yadif_ushort_param_5,
	.param .u32 yadif_ushort_param_6,
	.param .u32 yadif_ushort_param_7,
	.param .u32 yadif_ushort_param_8,
	.param .u32 yadif_ushort_param_9,
	.param .u32 yadif_ushort_param_10,
	.param .u8 yadif_ushort_param_11
)
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<15>;
	.reg .b32 	%r<250>;
	.reg .b64 	%rd<10>;


	ld.param.s8 	%rs1, [yadif_ushort_param_11];
	ld.param.u64 	%rd2, [yadif_ushort_param_0];
	ld.param.u64 	%rd3, [yadif_ushort_param_1];
	ld.param.u64 	%rd4, [yadif_ushort_param_2];
	ld.param.u64 	%rd5, [yadif_ushort_param_3];
	ld.param.u32 	%r57, [yadif_ushort_param_4];
	ld.param.u32 	%r58, [yadif_ushort_param_5];
	ld.param.u32 	%r54, [yadif_ushort_param_6];
	ld.param.u32 	%r55, [yadif_ushort_param_9];
	ld.param.u32 	%r56, [yadif_ushort_param_10];
	mov.u32 	%r59, %ntid.x;
	mov.u32 	%r60, %ctaid.x;
	mov.u32 	%r61, %tid.x;
	mad.lo.s32 	%r1, %r60, %r59, %r61;
	mov.u32 	%r62, %ntid.y;
	mov.u32 	%r63, %ctaid.y;
	mov.u32 	%r64, %tid.y;
	mad.lo.s32 	%r2, %r63, %r62, %r64;
	setp.ge.s32 	%p1, %r1, %r57;
	setp.ge.s32 	%p2, %r2, %r58;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB1_10;

	shr.u32 	%r65, %r2, 31;
	add.s32 	%r66, %r2, %r65;
	and.b32  	%r67, %r66, -2;
	sub.s32 	%r68, %r2, %r67;
	setp.eq.s32 	%p4, %r68, %r55;
	mad.lo.s32 	%r69, %r2, %r54, %r1;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r69, 2;
	add.s64 	%rd1, %rd6, %rd7;
	@%p4 bra 	$L__BB1_9;
	bra.uni 	$L__BB1_2;

$L__BB1_9:
	cvt.rn.f32.s32 	%f13, %r1;
	cvt.rn.f32.s32 	%f14, %r2;
	tex.2d.v4.u32.f32 	{%r242, %r243, %r244, %r245}, [%rd4, {%f13, %f14}];
	st.global.u16 	[%rd1], %r242;
	bra.uni 	$L__BB1_10;

$L__BB1_2:
	add.s32 	%r70, %r1, -3;
	cvt.rn.f32.s32 	%f4, %r70;
	add.s32 	%r71, %r2, -1;
	cvt.rn.f32.s32 	%f1, %r71;
	tex.2d.v4.u32.f32 	{%r3, %r4, %r5, %r6}, [%rd4, {%f4, %f1}];
	add.s32 	%r72, %r1, -2;
	cvt.rn.f32.s32 	%f5, %r72;
	tex.2d.v4.u32.f32 	{%r73, %r74, %r75, %r76}, [%rd4, {%f5, %f1}];
	add.s32 	%r77, %r1, -1;
	cvt.rn.f32.s32 	%f6, %r77;
	tex.2d.v4.u32.f32 	{%r78, %r79, %r80, %r81}, [%rd4, {%f6, %f1}];
	cvt.rn.f32.s32 	%f2, %r1;
	tex.2d.v4.u32.f32 	{%r82, %r83, %r84, %r85}, [%rd4, {%f2, %f1}];
	add.s32 	%r86, %r1, 1;
	cvt.rn.f32.s32 	%f7, %r86;
	tex.2d.v4.u32.f32 	{%r87, %r88, %r89, %r90}, [%rd4, {%f7, %f1}];
	add.s32 	%r91, %r1, 2;
	cvt.rn.f32.s32 	%f8, %r91;
	tex.2d.v4.u32.f32 	{%r7, %r8, %r9, %r10}, [%rd4, {%f8, %f1}];
	add.s32 	%r92, %r1, 3;
	cvt.rn.f32.s32 	%f9, %r92;
	tex.2d.v4.u32.f32 	{%r11, %r12, %r13, %r14}, [%rd4, {%f9, %f1}];
	add.s32 	%r93, %r2, 1;
	cvt.rn.f32.s32 	%f3, %r93;
	tex.2d.v4.u32.f32 	{%r15, %r16, %r17, %r18}, [%rd4, {%f4, %f3}];
	tex.2d.v4.u32.f32 	{%r19, %r20, %r21, %r22}, [%rd4, {%f5, %f3}];
	tex.2d.v4.u32.f32 	{%r94, %r95, %r96, %r97}, [%rd4, {%f6, %f3}];
	tex.2d.v4.u32.f32 	{%r98, %r99, %r100, %r101}, [%rd4, {%f2, %f3}];
	tex.2d.v4.u32.f32 	{%r102, %r103, %r104, %r105}, [%rd4, {%f7, %f3}];
	tex.2d.v4.u32.f32 	{%r106, %r107, %r108, %r109}, [%rd4, {%f8, %f3}];
	tex.2d.v4.u32.f32 	{%r23, %r24, %r25, %r26}, [%rd4, {%f9, %f3}];
	and.b32  	%r27, %r82, 65535;
	and.b32  	%r28, %r98, 65535;
	add.s32 	%r248, %r28, %r27;
	and.b32  	%r30, %r78, 65535;
	and.b32  	%r31, %r94, 65535;
	sub.s32 	%r110, %r30, %r31;
	abs.s32 	%r111, %r110;
	sub.s32 	%r112, %r27, %r28;
	abs.s32 	%r113, %r112;
	add.s32 	%r114, %r113, %r111;
	and.b32  	%r32, %r87, 65535;
	and.b32  	%r33, %r102, 65535;
	sub.s32 	%r115, %r32, %r33;
	abs.s32 	%r116, %r115;
	add.s32 	%r247, %r114, %r116;
	and.b32  	%r35, %r73, 65535;
	sub.s32 	%r117, %r35, %r28;
	abs.s32 	%r118, %r117;
	sub.s32 	%r119, %r30, %r33;
	abs.s32 	%r120, %r119;
	add.s32 	%r121, %r120, %r118;
	and.b32  	%r36, %r106, 65535;
	sub.s32 	%r122, %r27, %r36;
	abs.s32 	%r123, %r122;
	add.s32 	%r37, %r121, %r123;
	setp.ge.s32 	%p5, %r37, %r247;
	@%p5 bra 	$L__BB1_4;

	and.b32  	%r124, %r3, 65535;
	sub.s32 	%r125, %r124, %r33;
	abs.s32 	%r126, %r125;
	sub.s32 	%r127, %r35, %r36;
	abs.s32 	%r128, %r127;
	add.s32 	%r129, %r128, %r126;
	and.b32  	%r130, %r23, 65535;
	sub.s32 	%r131, %r30, %r130;
	abs.s32 	%r132, %r131;
	add.s32 	%r133, %r129, %r132;
	setp.lt.s32 	%p6, %r133, %r37;
	add.s32 	%r134, %r36, %r35;
	add.s32 	%r135, %r33, %r30;
	selp.b32 	%r248, %r134, %r135, %p6;
	min.s32 	%r247, %r133, %r37;

$L__BB1_4:
	and.b32  	%r42, %r19, 65535;
	sub.s32 	%r136, %r27, %r42;
	abs.s32 	%r137, %r136;
	sub.s32 	%r138, %r32, %r31;
	abs.s32 	%r139, %r138;
	add.s32 	%r140, %r139, %r137;
	and.b32  	%r43, %r7, 65535;
	sub.s32 	%r141, %r43, %r28;
	abs.s32 	%r142, %r141;
	add.s32 	%r44, %r140, %r142;
	setp.ge.s32 	%p7, %r44, %r247;
	@%p7 bra 	$L__BB1_6;

	add.s32 	%r143, %r31, %r32;
	and.b32  	%r144, %r15, 65535;
	sub.s32 	%r145, %r32, %r144;
	abs.s32 	%r146, %r145;
	sub.s32 	%r147, %r43, %r42;
	abs.s32 	%r148, %r147;
	add.s32 	%r149, %r148, %r146;
	and.b32  	%r150, %r11, 65535;
	sub.s32 	%r151, %r150, %r31;
	abs.s32 	%r152, %r151;
	add.s32 	%r153, %r149, %r152;
	setp.lt.s32 	%p8, %r153, %r44;
	add.s32 	%r154, %r42, %r43;
	selp.b32 	%r248, %r154, %r143, %p8;

$L__BB1_6:
	setp.eq.s32 	%p9, %r55, %r56;
	selp.b64 	%rd8, %rd4, %rd3, %p9;
	selp.b64 	%rd9, %rd5, %rd4, %p9;
	tex.2d.v4.u32.f32 	{%r155, %r156, %r157, %r158}, [%rd3, {%f2, %f1}];
	tex.2d.v4.u32.f32 	{%r159, %r160, %r161, %r162}, [%rd3, {%f2, %f3}];
	add.s32 	%r163, %r2, -2;
	cvt.rn.f32.s32 	%f10, %r163;
	tex.2d.v4.u32.f32 	{%r164, %r165, %r166, %r167}, [%rd8, {%f2, %f10}];
	cvt.rn.f32.s32 	%f11, %r2;
	tex.2d.v4.u32.f32 	{%r168, %r169, %r170, %r171}, [%rd8, {%f2, %f11}];
	add.s32 	%r172, %r2, 2;
	cvt.rn.f32.s32 	%f12, %r172;
	tex.2d.v4.u32.f32 	{%r173, %r174, %r175, %r176}, [%rd8, {%f2, %f12}];
	tex.2d.v4.u32.f32 	{%r177, %r178, %r179, %r180}, [%rd9, {%f2, %f10}];
	tex.2d.v4.u32.f32 	{%r181, %r182, %r183, %r184}, [%rd9, {%f2, %f11}];
	tex.2d.v4.u32.f32 	{%r185, %r186, %r187, %r188}, [%rd9, {%f2, %f12}];
	tex.2d.v4.u32.f32 	{%r189, %r190, %r191, %r192}, [%rd5, {%f2, %f1}];
	tex.2d.v4.u32.f32 	{%r193, %r194, %r195, %r196}, [%rd5, {%f2, %f3}];
	shr.u32 	%r47, %r248, 1;
	and.b32  	%r197, %r164, 65535;
	and.b32  	%r198, %r177, 65535;
	add.s32 	%r48, %r198, %r197;
	and.b32  	%r199, %r168, 65535;
	and.b32  	%r200, %r181, 65535;
	add.s32 	%r201, %r200, %r199;
	shr.u32 	%r49, %r201, 1;
	and.b32  	%r202, %r173, 65535;
	and.b32  	%r203, %r185, 65535;
	add.s32 	%r50, %r203, %r202;
	sub.s32 	%r204, %r199, %r200;
	abs.s32 	%r205, %r204;
	and.b32  	%r206, %r155, 65535;
	sub.s32 	%r207, %r206, %r27;
	abs.s32 	%r208, %r207;
	and.b32  	%r209, %r159, 65535;
	sub.s32 	%r210, %r209, %r28;
	abs.s32 	%r211, %r210;
	add.s32 	%r212, %r211, %r208;
	shr.u32 	%r213, %r212, 1;
	and.b32  	%r214, %r189, 65535;
	sub.s32 	%r215, %r214, %r27;
	abs.s32 	%r216, %r215;
	and.b32  	%r217, %r193, 65535;
	sub.s32 	%r218, %r28, %r217;
	abs.s32 	%r219, %r218;
	add.s32 	%r220, %r219, %r216;
	shr.u32 	%r221, %r220, 1;
	max.s32 	%r222, %r205, %r213;
	max.s32 	%r249, %r222, %r221;
	setp.ne.s16 	%p10, %rs1, 0;
	@%p10 bra 	$L__BB1_8;

	shr.u32 	%r223, %r50, 1;
	shr.u32 	%r224, %r48, 1;
	sub.s32 	%r225, %r224, %r27;
	sub.s32 	%r226, %r223, %r28;
	min.s32 	%r227, %r225, %r226;
	sub.s32 	%r228, %r49, %r27;
	sub.s32 	%r229, %r49, %r28;
	max.s32 	%r230, %r229, %r228;
	max.s32 	%r231, %r230, %r227;
	max.s32 	%r232, %r225, %r226;
	min.s32 	%r233, %r229, %r228;
	min.s32 	%r234, %r233, %r232;
	neg.s32 	%r235, %r231;
	max.s32 	%r236, %r249, %r234;
	max.s32 	%r249, %r236, %r235;

$L__BB1_8:
	add.s32 	%r237, %r249, %r49;
	setp.lt.s32 	%p11, %r237, %r47;
	selp.b32 	%r238, %r237, %r47, %p11;
	and.b32  	%r239, %r238, 65535;
	sub.s32 	%r240, %r49, %r249;
	setp.gt.s32 	%p12, %r240, %r239;
	selp.b32 	%r241, %r240, %r238, %p12;
	st.global.u16 	[%rd1], %r241;

$L__BB1_10:
	ret;

}
	// .globl	yadif_uchar2
.visible .entry yadif_uchar2(
	.param .u64 yadif_uchar2_param_0,
	.param .u64 yadif_uchar2_param_1,
	.param .u64 yadif_uchar2_param_2,
	.param .u64 yadif_uchar2_param_3,
	.param .u32 yadif_uchar2_param_4,
	.param .u32 yadif_uchar2_param_5,
	.param .u32 yadif_uchar2_param_6,
	.param .u32 yadif_uchar2_param_7,
	.param .u32 yadif_uchar2_param_8,
	.param .u32 yadif_uchar2_param_9,
	.param .u32 yadif_uchar2_param_10,
	.param .u8 yadif_uchar2_param_11
)
{
	.reg .pred 	%p<20>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<15>;
	.reg .b32 	%r<371>;
	.reg .b64 	%rd<10>;


	ld.param.s8 	%rs1, [yadif_uchar2_param_11];
	ld.param.u64 	%rd2, [yadif_uchar2_param_0];
	ld.param.u64 	%rd3, [yadif_uchar2_param_1];
	ld.param.u64 	%rd4, [yadif_uchar2_param_2];
	ld.param.u64 	%rd5, [yadif_uchar2_param_3];
	ld.param.u32 	%r154, [yadif_uchar2_param_4];
	ld.param.u32 	%r155, [yadif_uchar2_param_5];
	ld.param.u32 	%r151, [yadif_uchar2_param_6];
	ld.param.u32 	%r152, [yadif_uchar2_param_9];
	ld.param.u32 	%r153, [yadif_uchar2_param_10];
	mov.u32 	%r156, %ntid.x;
	mov.u32 	%r157, %ctaid.x;
	mov.u32 	%r158, %tid.x;
	mad.lo.s32 	%r1, %r157, %r156, %r158;
	mov.u32 	%r159, %ntid.y;
	mov.u32 	%r160, %ctaid.y;
	mov.u32 	%r161, %tid.y;
	mad.lo.s32 	%r2, %r160, %r159, %r161;
	setp.ge.s32 	%p1, %r1, %r154;
	setp.ge.s32 	%p2, %r2, %r155;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB2_16;

	shr.u32 	%r162, %r2, 31;
	add.s32 	%r163, %r2, %r162;
	and.b32  	%r164, %r163, -2;
	sub.s32 	%r165, %r2, %r164;
	setp.eq.s32 	%p4, %r165, %r152;
	mad.lo.s32 	%r166, %r2, %r151, %r1;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r166, 2;
	add.s64 	%rd1, %rd6, %rd7;
	@%p4 bra 	$L__BB2_15;
	bra.uni 	$L__BB2_2;

$L__BB2_15:
	cvt.rn.f32.s32 	%f13, %r1;
	cvt.rn.f32.s32 	%f14, %r2;
	tex.2d.v4.u32.f32 	{%r359, %r360, %r361, %r362}, [%rd4, {%f13, %f14}];
	cvt.u16.u32 	%rs4, %r360;
	cvt.u16.u32 	%rs5, %r359;
	st.global.v2.u8 	[%rd1], {%rs5, %rs4};
	bra.uni 	$L__BB2_16;

$L__BB2_2:
	add.s32 	%r167, %r1, -3;
	cvt.rn.f32.s32 	%f4, %r167;
	add.s32 	%r168, %r2, -1;
	cvt.rn.f32.s32 	%f1, %r168;
	tex.2d.v4.u32.f32 	{%r3, %r4, %r5, %r6}, [%rd4, {%f4, %f1}];
	add.s32 	%r169, %r1, -2;
	cvt.rn.f32.s32 	%f5, %r169;
	tex.2d.v4.u32.f32 	{%r7, %r8, %r9, %r10}, [%rd4, {%f5, %f1}];
	add.s32 	%r170, %r1, -1;
	cvt.rn.f32.s32 	%f6, %r170;
	tex.2d.v4.u32.f32 	{%r11, %r12, %r13, %r14}, [%rd4, {%f6, %f1}];
	cvt.rn.f32.s32 	%f2, %r1;
	tex.2d.v4.u32.f32 	{%r15, %r16, %r17, %r18}, [%rd4, {%f2, %f1}];
	add.s32 	%r171, %r1, 1;
	cvt.rn.f32.s32 	%f7, %r171;
	tex.2d.v4.u32.f32 	{%r19, %r20, %r21, %r22}, [%rd4, {%f7, %f1}];
	add.s32 	%r172, %r1, 2;
	cvt.rn.f32.s32 	%f8, %r172;
	tex.2d.v4.u32.f32 	{%r23, %r24, %r25, %r26}, [%rd4, {%f8, %f1}];
	add.s32 	%r173, %r1, 3;
	cvt.rn.f32.s32 	%f9, %r173;
	tex.2d.v4.u32.f32 	{%r27, %r28, %r29, %r30}, [%rd4, {%f9, %f1}];
	add.s32 	%r174, %r2, 1;
	cvt.rn.f32.s32 	%f3, %r174;
	tex.2d.v4.u32.f32 	{%r31, %r32, %r33, %r34}, [%rd4, {%f4, %f3}];
	tex.2d.v4.u32.f32 	{%r35, %r36, %r37, %r38}, [%rd4, {%f5, %f3}];
	tex.2d.v4.u32.f32 	{%r39, %r40, %r41, %r42}, [%rd4, {%f6, %f3}];
	tex.2d.v4.u32.f32 	{%r43, %r44, %r45, %r46}, [%rd4, {%f2, %f3}];
	tex.2d.v4.u32.f32 	{%r47, %r48, %r49, %r50}, [%rd4, {%f7, %f3}];
	tex.2d.v4.u32.f32 	{%r51, %r52, %r53, %r54}, [%rd4, {%f8, %f3}];
	tex.2d.v4.u32.f32 	{%r55, %r56, %r57, %r58}, [%rd4, {%f9, %f3}];
	and.b32  	%r59, %r15, 255;
	and.b32  	%r60, %r43, 255;
	add.s32 	%r365, %r60, %r59;
	and.b32  	%r62, %r11, 255;
	and.b32  	%r63, %r39, 255;
	sub.s32 	%r175, %r62, %r63;
	abs.s32 	%r176, %r175;
	sub.s32 	%r177, %r59, %r60;
	abs.s32 	%r178, %r177;
	add.s32 	%r179, %r178, %r176;
	and.b32  	%r64, %r19, 255;
	and.b32  	%r65, %r47, 255;
	sub.s32 	%r180, %r64, %r65;
	abs.s32 	%r181, %r180;
	add.s32 	%r364, %r179, %r181;
	and.b32  	%r67, %r7, 255;
	sub.s32 	%r182, %r67, %r60;
	abs.s32 	%r183, %r182;
	sub.s32 	%r184, %r62, %r65;
	abs.s32 	%r185, %r184;
	add.s32 	%r186, %r185, %r183;
	and.b32  	%r68, %r51, 255;
	sub.s32 	%r187, %r59, %r68;
	abs.s32 	%r188, %r187;
	add.s32 	%r69, %r186, %r188;
	setp.ge.s32 	%p5, %r69, %r364;
	@%p5 bra 	$L__BB2_4;

	and.b32  	%r189, %r3, 255;
	sub.s32 	%r190, %r189, %r65;
	abs.s32 	%r191, %r190;
	sub.s32 	%r192, %r67, %r68;
	abs.s32 	%r193, %r192;
	add.s32 	%r194, %r193, %r191;
	and.b32  	%r195, %r55, 255;
	sub.s32 	%r196, %r62, %r195;
	abs.s32 	%r197, %r196;
	add.s32 	%r198, %r194, %r197;
	setp.lt.s32 	%p6, %r198, %r69;
	add.s32 	%r199, %r68, %r67;
	add.s32 	%r200, %r65, %r62;
	selp.b32 	%r365, %r199, %r200, %p6;
	min.s32 	%r364, %r198, %r69;

$L__BB2_4:
	and.b32  	%r74, %r35, 255;
	sub.s32 	%r201, %r59, %r74;
	abs.s32 	%r202, %r201;
	sub.s32 	%r203, %r64, %r63;
	abs.s32 	%r204, %r203;
	add.s32 	%r205, %r204, %r202;
	and.b32  	%r75, %r23, 255;
	sub.s32 	%r206, %r75, %r60;
	abs.s32 	%r207, %r206;
	add.s32 	%r76, %r205, %r207;
	setp.ge.s32 	%p7, %r76, %r364;
	@%p7 bra 	$L__BB2_6;

	add.s32 	%r208, %r63, %r64;
	and.b32  	%r209, %r31, 255;
	sub.s32 	%r210, %r64, %r209;
	abs.s32 	%r211, %r210;
	sub.s32 	%r212, %r75, %r74;
	abs.s32 	%r213, %r212;
	add.s32 	%r214, %r213, %r211;
	and.b32  	%r215, %r27, 255;
	sub.s32 	%r216, %r215, %r63;
	abs.s32 	%r217, %r216;
	add.s32 	%r218, %r214, %r217;
	setp.lt.s32 	%p8, %r218, %r76;
	add.s32 	%r219, %r74, %r75;
	selp.b32 	%r365, %r219, %r208, %p8;

$L__BB2_6:
	and.b32  	%r79, %r44, 255;
	and.b32  	%r80, %r16, 255;
	add.s32 	%r368, %r79, %r80;
	and.b32  	%r82, %r40, 255;
	and.b32  	%r83, %r12, 255;
	sub.s32 	%r220, %r83, %r82;
	abs.s32 	%r221, %r220;
	sub.s32 	%r222, %r80, %r79;
	abs.s32 	%r223, %r222;
	add.s32 	%r224, %r223, %r221;
	and.b32  	%r84, %r48, 255;
	and.b32  	%r85, %r20, 255;
	sub.s32 	%r225, %r85, %r84;
	abs.s32 	%r226, %r225;
	add.s32 	%r367, %r224, %r226;
	and.b32  	%r87, %r8, 255;
	sub.s32 	%r227, %r87, %r79;
	abs.s32 	%r228, %r227;
	sub.s32 	%r229, %r83, %r84;
	abs.s32 	%r230, %r229;
	add.s32 	%r231, %r230, %r228;
	and.b32  	%r88, %r52, 255;
	sub.s32 	%r232, %r80, %r88;
	abs.s32 	%r233, %r232;
	add.s32 	%r89, %r231, %r233;
	setp.ge.s32 	%p9, %r89, %r367;
	@%p9 bra 	$L__BB2_8;

	add.s32 	%r234, %r84, %r83;
	and.b32  	%r235, %r4, 255;
	sub.s32 	%r236, %r235, %r84;
	abs.s32 	%r237, %r236;
	sub.s32 	%r238, %r87, %r88;
	abs.s32 	%r239, %r238;
	add.s32 	%r240, %r239, %r237;
	and.b32  	%r241, %r56, 255;
	sub.s32 	%r242, %r83, %r241;
	abs.s32 	%r243, %r242;
	add.s32 	%r244, %r240, %r243;
	setp.lt.s32 	%p10, %r244, %r89;
	add.s32 	%r245, %r88, %r87;
	selp.b32 	%r368, %r245, %r234, %p10;
	min.s32 	%r367, %r244, %r89;

$L__BB2_8:
	and.b32  	%r94, %r36, 255;
	sub.s32 	%r246, %r80, %r94;
	abs.s32 	%r247, %r246;
	sub.s32 	%r248, %r85, %r82;
	abs.s32 	%r249, %r248;
	add.s32 	%r250, %r249, %r247;
	and.b32  	%r95, %r24, 255;
	sub.s32 	%r251, %r95, %r79;
	abs.s32 	%r252, %r251;
	add.s32 	%r96, %r250, %r252;
	setp.ge.s32 	%p11, %r96, %r367;
	@%p11 bra 	$L__BB2_10;

	add.s32 	%r253, %r82, %r85;
	and.b32  	%r254, %r32, 255;
	sub.s32 	%r255, %r85, %r254;
	abs.s32 	%r256, %r255;
	sub.s32 	%r257, %r95, %r94;
	abs.s32 	%r258, %r257;
	add.s32 	%r259, %r258, %r256;
	and.b32  	%r260, %r28, 255;
	sub.s32 	%r261, %r260, %r82;
	abs.s32 	%r262, %r261;
	add.s32 	%r263, %r259, %r262;
	setp.lt.s32 	%p12, %r263, %r96;
	add.s32 	%r264, %r94, %r95;
	selp.b32 	%r368, %r264, %r253, %p12;

$L__BB2_10:
	setp.eq.s32 	%p13, %r152, %r153;
	selp.b64 	%rd8, %rd4, %rd3, %p13;
	selp.b64 	%rd9, %rd5, %rd4, %p13;
	tex.2d.v4.u32.f32 	{%r99, %r100, %r101, %r102}, [%rd3, {%f2, %f1}];
	tex.2d.v4.u32.f32 	{%r103, %r104, %r105, %r106}, [%rd3, {%f2, %f3}];
	add.s32 	%r265, %r2, -2;
	cvt.rn.f32.s32 	%f10, %r265;
	tex.2d.v4.u32.f32 	{%r107, %r108, %r109, %r110}, [%rd8, {%f2, %f10}];
	cvt.rn.f32.s32 	%f11, %r2;
	tex.2d.v4.u32.f32 	{%r111, %r112, %r113, %r114}, [%rd8, {%f2, %f11}];
	add.s32 	%r266, %r2, 2;
	cvt.rn.f32.s32 	%f12, %r266;
	tex.2d.v4.u32.f32 	{%r115, %r116, %r117, %r118}, [%rd8, {%f2, %f12}];
	tex.2d.v4.u32.f32 	{%r119, %r120, %r121, %r122}, [%rd9, {%f2, %f10}];
	tex.2d.v4.u32.f32 	{%r123, %r124, %r125, %r126}, [%rd9, {%f2, %f11}];
	tex.2d.v4.u32.f32 	{%r127, %r128, %r129, %r130}, [%rd9, {%f2, %f12}];
	tex.2d.v4.u32.f32 	{%r131, %r132, %r133, %r134}, [%rd5, {%f2, %f1}];
	tex.2d.v4.u32.f32 	{%r135, %r136, %r137, %r138}, [%rd5, {%f2, %f3}];
	and.b32  	%r267, %r111, 255;
	and.b32  	%r268, %r123, 255;
	add.s32 	%r269, %r268, %r267;
	shr.u32 	%r139, %r269, 1;
	sub.s32 	%r270, %r267, %r268;
	abs.s32 	%r271, %r270;
	and.b32  	%r272, %r99, 255;
	sub.s32 	%r273, %r272, %r59;
	abs.s32 	%r274, %r273;
	and.b32  	%r275, %r103, 255;
	sub.s32 	%r276, %r275, %r60;
	abs.s32 	%r277, %r276;
	add.s32 	%r278, %r277, %r274;
	shr.u32 	%r279, %r278, 1;
	and.b32  	%r280, %r131, 255;
	sub.s32 	%r281, %r280, %r59;
	abs.s32 	%r282, %r281;
	and.b32  	%r283, %r135, 255;
	sub.s32 	%r284, %r60, %r283;
	abs.s32 	%r285, %r284;
	add.s32 	%r286, %r285, %r282;
	shr.u32 	%r287, %r286, 1;
	max.s32 	%r288, %r271, %r279;
	max.s32 	%r369, %r288, %r287;
	setp.ne.s16 	%p14, %rs1, 0;
	@%p14 bra 	$L__BB2_12;

	and.b32  	%r289, %r127, 255;
	and.b32  	%r290, %r115, 255;
	add.s32 	%r291, %r289, %r290;
	shr.u32 	%r292, %r291, 1;
	and.b32  	%r293, %r119, 255;
	and.b32  	%r294, %r107, 255;
	add.s32 	%r295, %r293, %r294;
	shr.u32 	%r296, %r295, 1;
	sub.s32 	%r297, %r296, %r59;
	sub.s32 	%r298, %r292, %r60;
	min.s32 	%r299, %r297, %r298;
	sub.s32 	%r300, %r139, %r59;
	sub.s32 	%r301, %r139, %r60;
	max.s32 	%r302, %r301, %r300;
	max.s32 	%r303, %r302, %r299;
	max.s32 	%r304, %r297, %r298;
	min.s32 	%r305, %r301, %r300;
	min.s32 	%r306, %r305, %r304;
	neg.s32 	%r307, %r303;
	max.s32 	%r308, %r369, %r306;
	max.s32 	%r369, %r308, %r307;

$L__BB2_12:
	shr.u32 	%r143, %r368, 1;
	add.s32 	%r309, %r369, %r139;
	shr.u32 	%r310, %r365, 1;
	setp.lt.s32 	%p15, %r309, %r310;
	selp.b32 	%r311, %r309, %r310, %p15;
	and.b32  	%r312, %r311, 255;
	sub.s32 	%r313, %r139, %r369;
	setp.gt.s32 	%p16, %r313, %r312;
	selp.b32 	%r144, %r313, %r311, %p16;
	and.b32  	%r314, %r120, 255;
	and.b32  	%r315, %r108, 255;
	add.s32 	%r145, %r314, %r315;
	and.b32  	%r316, %r124, 255;
	and.b32  	%r317, %r112, 255;
	add.s32 	%r318, %r316, %r317;
	shr.u32 	%r146, %r318, 1;
	and.b32  	%r319, %r128, 255;
	and.b32  	%r320, %r116, 255;
	add.s32 	%r147, %r319, %r320;
	sub.s32 	%r321, %r317, %r316;
	abs.s32 	%r322, %r321;
	and.b32  	%r323, %r100, 255;
	sub.s32 	%r324, %r323, %r80;
	abs.s32 	%r325, %r324;
	and.b32  	%r326, %r104, 255;
	sub.s32 	%r327, %r326, %r79;
	abs.s32 	%r328, %r327;
	add.s32 	%r329, %r328, %r325;
	shr.u32 	%r330, %r329, 1;
	and.b32  	%r331, %r132, 255;
	sub.s32 	%r332, %r331, %r80;
	abs.s32 	%r333, %r332;
	and.b32  	%r334, %r136, 255;
	sub.s32 	%r335, %r79, %r334;
	abs.s32 	%r336, %r335;
	add.s32 	%r337, %r336, %r333;
	shr.u32 	%r338, %r337, 1;
	max.s32 	%r339, %r322, %r330;
	max.s32 	%r370, %r339, %r338;
	@%p14 bra 	$L__BB2_14;

	shr.u32 	%r340, %r147, 1;
	shr.u32 	%r341, %r145, 1;
	sub.s32 	%r342, %r341, %r80;
	sub.s32 	%r343, %r340, %r79;
	min.s32 	%r344, %r342, %r343;
	sub.s32 	%r345, %r146, %r80;
	sub.s32 	%r346, %r146, %r79;
	max.s32 	%r347, %r346, %r345;
	max.s32 	%r348, %r347, %r344;
	max.s32 	%r349, %r342, %r343;
	min.s32 	%r350, %r346, %r345;
	min.s32 	%r351, %r350, %r349;
	neg.s32 	%r352, %r348;
	max.s32 	%r353, %r370, %r351;
	max.s32 	%r370, %r353, %r352;

$L__BB2_14:
	add.s32 	%r354, %r370, %r146;
	setp.lt.s32 	%p18, %r354, %r143;
	selp.b32 	%r355, %r354, %r143, %p18;
	and.b32  	%r356, %r355, 255;
	sub.s32 	%r357, %r146, %r370;
	setp.gt.s32 	%p19, %r357, %r356;
	selp.b32 	%r358, %r357, %r355, %p19;
	cvt.u16.u32 	%rs2, %r358;
	cvt.u16.u32 	%rs3, %r144;
	st.global.v2.u8 	[%rd1], {%rs3, %rs2};

$L__BB2_16:
	ret;

}
	// .globl	yadif_ushort2
.visible .entry yadif_ushort2(
	.param .u64 yadif_ushort2_param_0,
	.param .u64 yadif_ushort2_param_1,
	.param .u64 yadif_ushort2_param_2,
	.param .u64 yadif_ushort2_param_3,
	.param .u32 yadif_ushort2_param_4,
	.param .u32 yadif_ushort2_param_5,
	.param .u32 yadif_ushort2_param_6,
	.param .u32 yadif_ushort2_param_7,
	.param .u32 yadif_ushort2_param_8,
	.param .u32 yadif_ushort2_param_9,
	.param .u32 yadif_ushort2_param_10,
	.param .u8 yadif_ushort2_param_11
)
{
	.reg .pred 	%p<20>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<15>;
	.reg .b32 	%r<371>;
	.reg .b64 	%rd<10>;


	ld.param.s8 	%rs1, [yadif_ushort2_param_11];
	ld.param.u64 	%rd2, [yadif_ushort2_param_0];
	ld.param.u64 	%rd3, [yadif_ushort2_param_1];
	ld.param.u64 	%rd4, [yadif_ushort2_param_2];
	ld.param.u64 	%rd5, [yadif_ushort2_param_3];
	ld.param.u32 	%r154, [yadif_ushort2_param_4];
	ld.param.u32 	%r155, [yadif_ushort2_param_5];
	ld.param.u32 	%r151, [yadif_ushort2_param_6];
	ld.param.u32 	%r152, [yadif_ushort2_param_9];
	ld.param.u32 	%r153, [yadif_ushort2_param_10];
	mov.u32 	%r156, %ntid.x;
	mov.u32 	%r157, %ctaid.x;
	mov.u32 	%r158, %tid.x;
	mad.lo.s32 	%r1, %r157, %r156, %r158;
	mov.u32 	%r159, %ntid.y;
	mov.u32 	%r160, %ctaid.y;
	mov.u32 	%r161, %tid.y;
	mad.lo.s32 	%r2, %r160, %r159, %r161;
	setp.ge.s32 	%p1, %r1, %r154;
	setp.ge.s32 	%p2, %r2, %r155;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB3_16;

	shr.u32 	%r162, %r2, 31;
	add.s32 	%r163, %r2, %r162;
	and.b32  	%r164, %r163, -2;
	sub.s32 	%r165, %r2, %r164;
	setp.eq.s32 	%p4, %r165, %r152;
	mad.lo.s32 	%r166, %r2, %r151, %r1;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r166, 4;
	add.s64 	%rd1, %rd6, %rd7;
	@%p4 bra 	$L__BB3_15;
	bra.uni 	$L__BB3_2;

$L__BB3_15:
	cvt.rn.f32.s32 	%f13, %r1;
	cvt.rn.f32.s32 	%f14, %r2;
	tex.2d.v4.u32.f32 	{%r359, %r360, %r361, %r362}, [%rd4, {%f13, %f14}];
	cvt.u16.u32 	%rs4, %r360;
	cvt.u16.u32 	%rs5, %r359;
	st.global.v2.u16 	[%rd1], {%rs5, %rs4};
	bra.uni 	$L__BB3_16;

$L__BB3_2:
	add.s32 	%r167, %r1, -3;
	cvt.rn.f32.s32 	%f4, %r167;
	add.s32 	%r168, %r2, -1;
	cvt.rn.f32.s32 	%f1, %r168;
	tex.2d.v4.u32.f32 	{%r3, %r4, %r5, %r6}, [%rd4, {%f4, %f1}];
	add.s32 	%r169, %r1, -2;
	cvt.rn.f32.s32 	%f5, %r169;
	tex.2d.v4.u32.f32 	{%r7, %r8, %r9, %r10}, [%rd4, {%f5, %f1}];
	add.s32 	%r170, %r1, -1;
	cvt.rn.f32.s32 	%f6, %r170;
	tex.2d.v4.u32.f32 	{%r11, %r12, %r13, %r14}, [%rd4, {%f6, %f1}];
	cvt.rn.f32.s32 	%f2, %r1;
	tex.2d.v4.u32.f32 	{%r15, %r16, %r17, %r18}, [%rd4, {%f2, %f1}];
	add.s32 	%r171, %r1, 1;
	cvt.rn.f32.s32 	%f7, %r171;
	tex.2d.v4.u32.f32 	{%r19, %r20, %r21, %r22}, [%rd4, {%f7, %f1}];
	add.s32 	%r172, %r1, 2;
	cvt.rn.f32.s32 	%f8, %r172;
	tex.2d.v4.u32.f32 	{%r23, %r24, %r25, %r26}, [%rd4, {%f8, %f1}];
	add.s32 	%r173, %r1, 3;
	cvt.rn.f32.s32 	%f9, %r173;
	tex.2d.v4.u32.f32 	{%r27, %r28, %r29, %r30}, [%rd4, {%f9, %f1}];
	add.s32 	%r174, %r2, 1;
	cvt.rn.f32.s32 	%f3, %r174;
	tex.2d.v4.u32.f32 	{%r31, %r32, %r33, %r34}, [%rd4, {%f4, %f3}];
	tex.2d.v4.u32.f32 	{%r35, %r36, %r37, %r38}, [%rd4, {%f5, %f3}];
	tex.2d.v4.u32.f32 	{%r39, %r40, %r41, %r42}, [%rd4, {%f6, %f3}];
	tex.2d.v4.u32.f32 	{%r43, %r44, %r45, %r46}, [%rd4, {%f2, %f3}];
	tex.2d.v4.u32.f32 	{%r47, %r48, %r49, %r50}, [%rd4, {%f7, %f3}];
	tex.2d.v4.u32.f32 	{%r51, %r52, %r53, %r54}, [%rd4, {%f8, %f3}];
	tex.2d.v4.u32.f32 	{%r55, %r56, %r57, %r58}, [%rd4, {%f9, %f3}];
	and.b32  	%r59, %r15, 65535;
	and.b32  	%r60, %r43, 65535;
	add.s32 	%r365, %r60, %r59;
	and.b32  	%r62, %r11, 65535;
	and.b32  	%r63, %r39, 65535;
	sub.s32 	%r175, %r62, %r63;
	abs.s32 	%r176, %r175;
	sub.s32 	%r177, %r59, %r60;
	abs.s32 	%r178, %r177;
	add.s32 	%r179, %r178, %r176;
	and.b32  	%r64, %r19, 65535;
	and.b32  	%r65, %r47, 65535;
	sub.s32 	%r180, %r64, %r65;
	abs.s32 	%r181, %r180;
	add.s32 	%r364, %r179, %r181;
	and.b32  	%r67, %r7, 65535;
	sub.s32 	%r182, %r67, %r60;
	abs.s32 	%r183, %r182;
	sub.s32 	%r184, %r62, %r65;
	abs.s32 	%r185, %r184;
	add.s32 	%r186, %r185, %r183;
	and.b32  	%r68, %r51, 65535;
	sub.s32 	%r187, %r59, %r68;
	abs.s32 	%r188, %r187;
	add.s32 	%r69, %r186, %r188;
	setp.ge.s32 	%p5, %r69, %r364;
	@%p5 bra 	$L__BB3_4;

	and.b32  	%r189, %r3, 65535;
	sub.s32 	%r190, %r189, %r65;
	abs.s32 	%r191, %r190;
	sub.s32 	%r192, %r67, %r68;
	abs.s32 	%r193, %r192;
	add.s32 	%r194, %r193, %r191;
	and.b32  	%r195, %r55, 65535;
	sub.s32 	%r196, %r62, %r195;
	abs.s32 	%r197, %r196;
	add.s32 	%r198, %r194, %r197;
	setp.lt.s32 	%p6, %r198, %r69;
	add.s32 	%r199, %r68, %r67;
	add.s32 	%r200, %r65, %r62;
	selp.b32 	%r365, %r199, %r200, %p6;
	min.s32 	%r364, %r198, %r69;

$L__BB3_4:
	and.b32  	%r74, %r35, 65535;
	sub.s32 	%r201, %r59, %r74;
	abs.s32 	%r202, %r201;
	sub.s32 	%r203, %r64, %r63;
	abs.s32 	%r204, %r203;
	add.s32 	%r205, %r204, %r202;
	and.b32  	%r75, %r23, 65535;
	sub.s32 	%r206, %r75, %r60;
	abs.s32 	%r207, %r206;
	add.s32 	%r76, %r205, %r207;
	setp.ge.s32 	%p7, %r76, %r364;
	@%p7 bra 	$L__BB3_6;

	add.s32 	%r208, %r63, %r64;
	and.b32  	%r209, %r31, 65535;
	sub.s32 	%r210, %r64, %r209;
	abs.s32 	%r211, %r210;
	sub.s32 	%r212, %r75, %r74;
	abs.s32 	%r213, %r212;
	add.s32 	%r214, %r213, %r211;
	and.b32  	%r215, %r27, 65535;
	sub.s32 	%r216, %r215, %r63;
	abs.s32 	%r217, %r216;
	add.s32 	%r218, %r214, %r217;
	setp.lt.s32 	%p8, %r218, %r76;
	add.s32 	%r219, %r74, %r75;
	selp.b32 	%r365, %r219, %r208, %p8;

$L__BB3_6:
	and.b32  	%r79, %r44, 65535;
	and.b32  	%r80, %r16, 65535;
	add.s32 	%r368, %r79, %r80;
	and.b32  	%r82, %r40, 65535;
	and.b32  	%r83, %r12, 65535;
	sub.s32 	%r220, %r83, %r82;
	abs.s32 	%r221, %r220;
	sub.s32 	%r222, %r80, %r79;
	abs.s32 	%r223, %r222;
	add.s32 	%r224, %r223, %r221;
	and.b32  	%r84, %r48, 65535;
	and.b32  	%r85, %r20, 65535;
	sub.s32 	%r225, %r85, %r84;
	abs.s32 	%r226, %r225;
	add.s32 	%r367, %r224, %r226;
	and.b32  	%r87, %r8, 65535;
	sub.s32 	%r227, %r87, %r79;
	abs.s32 	%r228, %r227;
	sub.s32 	%r229, %r83, %r84;
	abs.s32 	%r230, %r229;
	add.s32 	%r231, %r230, %r228;
	and.b32  	%r88, %r52, 65535;
	sub.s32 	%r232, %r80, %r88;
	abs.s32 	%r233, %r232;
	add.s32 	%r89, %r231, %r233;
	setp.ge.s32 	%p9, %r89, %r367;
	@%p9 bra 	$L__BB3_8;

	add.s32 	%r234, %r84, %r83;
	and.b32  	%r235, %r4, 65535;
	sub.s32 	%r236, %r235, %r84;
	abs.s32 	%r237, %r236;
	sub.s32 	%r238, %r87, %r88;
	abs.s32 	%r239, %r238;
	add.s32 	%r240, %r239, %r237;
	and.b32  	%r241, %r56, 65535;
	sub.s32 	%r242, %r83, %r241;
	abs.s32 	%r243, %r242;
	add.s32 	%r244, %r240, %r243;
	setp.lt.s32 	%p10, %r244, %r89;
	add.s32 	%r245, %r88, %r87;
	selp.b32 	%r368, %r245, %r234, %p10;
	min.s32 	%r367, %r244, %r89;

$L__BB3_8:
	and.b32  	%r94, %r36, 65535;
	sub.s32 	%r246, %r80, %r94;
	abs.s32 	%r247, %r246;
	sub.s32 	%r248, %r85, %r82;
	abs.s32 	%r249, %r248;
	add.s32 	%r250, %r249, %r247;
	and.b32  	%r95, %r24, 65535;
	sub.s32 	%r251, %r95, %r79;
	abs.s32 	%r252, %r251;
	add.s32 	%r96, %r250, %r252;
	setp.ge.s32 	%p11, %r96, %r367;
	@%p11 bra 	$L__BB3_10;

	add.s32 	%r253, %r82, %r85;
	and.b32  	%r254, %r32, 65535;
	sub.s32 	%r255, %r85, %r254;
	abs.s32 	%r256, %r255;
	sub.s32 	%r257, %r95, %r94;
	abs.s32 	%r258, %r257;
	add.s32 	%r259, %r258, %r256;
	and.b32  	%r260, %r28, 65535;
	sub.s32 	%r261, %r260, %r82;
	abs.s32 	%r262, %r261;
	add.s32 	%r263, %r259, %r262;
	setp.lt.s32 	%p12, %r263, %r96;
	add.s32 	%r264, %r94, %r95;
	selp.b32 	%r368, %r264, %r253, %p12;

$L__BB3_10:
	setp.eq.s32 	%p13, %r152, %r153;
	selp.b64 	%rd8, %rd4, %rd3, %p13;
	selp.b64 	%rd9, %rd5, %rd4, %p13;
	tex.2d.v4.u32.f32 	{%r99, %r100, %r101, %r102}, [%rd3, {%f2, %f1}];
	tex.2d.v4.u32.f32 	{%r103, %r104, %r105, %r106}, [%rd3, {%f2, %f3}];
	add.s32 	%r265, %r2, -2;
	cvt.rn.f32.s32 	%f10, %r265;
	tex.2d.v4.u32.f32 	{%r107, %r108, %r109, %r110}, [%rd8, {%f2, %f10}];
	cvt.rn.f32.s32 	%f11, %r2;
	tex.2d.v4.u32.f32 	{%r111, %r112, %r113, %r114}, [%rd8, {%f2, %f11}];
	add.s32 	%r266, %r2, 2;
	cvt.rn.f32.s32 	%f12, %r266;
	tex.2d.v4.u32.f32 	{%r115, %r116, %r117, %r118}, [%rd8, {%f2, %f12}];
	tex.2d.v4.u32.f32 	{%r119, %r120, %r121, %r122}, [%rd9, {%f2, %f10}];
	tex.2d.v4.u32.f32 	{%r123, %r124, %r125, %r126}, [%rd9, {%f2, %f11}];
	tex.2d.v4.u32.f32 	{%r127, %r128, %r129, %r130}, [%rd9, {%f2, %f12}];
	tex.2d.v4.u32.f32 	{%r131, %r132, %r133, %r134}, [%rd5, {%f2, %f1}];
	tex.2d.v4.u32.f32 	{%r135, %r136, %r137, %r138}, [%rd5, {%f2, %f3}];
	and.b32  	%r267, %r111, 65535;
	and.b32  	%r268, %r123, 65535;
	add.s32 	%r269, %r268, %r267;
	shr.u32 	%r139, %r269, 1;
	sub.s32 	%r270, %r267, %r268;
	abs.s32 	%r271, %r270;
	and.b32  	%r272, %r99, 65535;
	sub.s32 	%r273, %r272, %r59;
	abs.s32 	%r274, %r273;
	and.b32  	%r275, %r103, 65535;
	sub.s32 	%r276, %r275, %r60;
	abs.s32 	%r277, %r276;
	add.s32 	%r278, %r277, %r274;
	shr.u32 	%r279, %r278, 1;
	and.b32  	%r280, %r131, 65535;
	sub.s32 	%r281, %r280, %r59;
	abs.s32 	%r282, %r281;
	and.b32  	%r283, %r135, 65535;
	sub.s32 	%r284, %r60, %r283;
	abs.s32 	%r285, %r284;
	add.s32 	%r286, %r285, %r282;
	shr.u32 	%r287, %r286, 1;
	max.s32 	%r288, %r271, %r279;
	max.s32 	%r369, %r288, %r287;
	setp.ne.s16 	%p14, %rs1, 0;
	@%p14 bra 	$L__BB3_12;

	and.b32  	%r289, %r127, 65535;
	and.b32  	%r290, %r115, 65535;
	add.s32 	%r291, %r289, %r290;
	shr.u32 	%r292, %r291, 1;
	and.b32  	%r293, %r119, 65535;
	and.b32  	%r294, %r107, 65535;
	add.s32 	%r295, %r293, %r294;
	shr.u32 	%r296, %r295, 1;
	sub.s32 	%r297, %r296, %r59;
	sub.s32 	%r298, %r292, %r60;
	min.s32 	%r299, %r297, %r298;
	sub.s32 	%r300, %r139, %r59;
	sub.s32 	%r301, %r139, %r60;
	max.s32 	%r302, %r301, %r300;
	max.s32 	%r303, %r302, %r299;
	max.s32 	%r304, %r297, %r298;
	min.s32 	%r305, %r301, %r300;
	min.s32 	%r306, %r305, %r304;
	neg.s32 	%r307, %r303;
	max.s32 	%r308, %r369, %r306;
	max.s32 	%r369, %r308, %r307;

$L__BB3_12:
	shr.u32 	%r143, %r368, 1;
	add.s32 	%r309, %r369, %r139;
	shr.u32 	%r310, %r365, 1;
	setp.lt.s32 	%p15, %r309, %r310;
	selp.b32 	%r311, %r309, %r310, %p15;
	and.b32  	%r312, %r311, 65535;
	sub.s32 	%r313, %r139, %r369;
	setp.gt.s32 	%p16, %r313, %r312;
	selp.b32 	%r144, %r313, %r311, %p16;
	and.b32  	%r314, %r120, 65535;
	and.b32  	%r315, %r108, 65535;
	add.s32 	%r145, %r314, %r315;
	and.b32  	%r316, %r124, 65535;
	and.b32  	%r317, %r112, 65535;
	add.s32 	%r318, %r316, %r317;
	shr.u32 	%r146, %r318, 1;
	and.b32  	%r319, %r128, 65535;
	and.b32  	%r320, %r116, 65535;
	add.s32 	%r147, %r319, %r320;
	sub.s32 	%r321, %r317, %r316;
	abs.s32 	%r322, %r321;
	and.b32  	%r323, %r100, 65535;
	sub.s32 	%r324, %r323, %r80;
	abs.s32 	%r325, %r324;
	and.b32  	%r326, %r104, 65535;
	sub.s32 	%r327, %r326, %r79;
	abs.s32 	%r328, %r327;
	add.s32 	%r329, %r328, %r325;
	shr.u32 	%r330, %r329, 1;
	and.b32  	%r331, %r132, 65535;
	sub.s32 	%r332, %r331, %r80;
	abs.s32 	%r333, %r332;
	and.b32  	%r334, %r136, 65535;
	sub.s32 	%r335, %r79, %r334;
	abs.s32 	%r336, %r335;
	add.s32 	%r337, %r336, %r333;
	shr.u32 	%r338, %r337, 1;
	max.s32 	%r339, %r322, %r330;
	max.s32 	%r370, %r339, %r338;
	@%p14 bra 	$L__BB3_14;

	shr.u32 	%r340, %r147, 1;
	shr.u32 	%r341, %r145, 1;
	sub.s32 	%r342, %r341, %r80;
	sub.s32 	%r343, %r340, %r79;
	min.s32 	%r344, %r342, %r343;
	sub.s32 	%r345, %r146, %r80;
	sub.s32 	%r346, %r146, %r79;
	max.s32 	%r347, %r346, %r345;
	max.s32 	%r348, %r347, %r344;
	max.s32 	%r349, %r342, %r343;
	min.s32 	%r350, %r346, %r345;
	min.s32 	%r351, %r350, %r349;
	neg.s32 	%r352, %r348;
	max.s32 	%r353, %r370, %r351;
	max.s32 	%r370, %r353, %r352;

$L__BB3_14:
	add.s32 	%r354, %r370, %r146;
	setp.lt.s32 	%p18, %r354, %r143;
	selp.b32 	%r355, %r354, %r143, %p18;
	and.b32  	%r356, %r355, 65535;
	sub.s32 	%r357, %r146, %r370;
	setp.gt.s32 	%p19, %r357, %r356;
	selp.b32 	%r358, %r357, %r355, %p19;
	cvt.u16.u32 	%rs2, %r358;
	cvt.u16.u32 	%rs3, %r144;
	st.global.v2.u16 	[%rd1], {%rs3, %rs2};

$L__BB3_16:
	ret;

}

